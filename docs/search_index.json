[["examples.html", "Chapter 3 Examples 3.1 Example 1: Regression 3.2 dbarts package 3.3 tidymodels package 3.4 Example 2: Classification 3.5 dbarts package 3.6 tidymodels package 3.7 References", " Chapter 3 Examples 3.1 Example 1: Regression This example is inspired by the blog post “The Effect of Childhood Education on Wealth: Modeling with Bayesian Additive Regression Trees (BART)” on R-bloggers by Selcuk Disci. We aimed to explore how enrollment rates in early childhood education are associated with household net worth across all countries involved in the organisation of economic co-operation and development (OECD), using datasets provided by this organization. The OECD collects data on enrollment rates in early childhood education and household net worth from its member countries every year from 2000 to 2020 through standardized surveys and national statistics, ensuring consistent and comparable data across all countries involved. According to OECD, the enrollment rates for each childhood age group, 3-year-old, 4-year-old, and 5-year-old are calculated by dividing the number of students enrolled in early childhood education and care (ECEC) of a particular age group by the total population of that age group. This calculation does not distinguish between full-time and part-time enrollment. The household net worth indicator first calculates the overall financial status of households by measuring the total value of their assets (both financial, like stocks and savings, and non-financial, like real estate) and subtracting the total value of their outstanding debts (such as loans and mortgages). This result is then presented as a percentage of the households’ annual income. Essentially, this indicator provides a snapshot of the economic health and financial stability of households by showing how much wealth they have in relation to how much they earn each year. We start here by loading some packages for the data and modeling, as well as cleaning and wrangling the data. # install.packages(&quot;countrycode&quot;) # install.packages(&quot;DALEXtra&quot;) library(tidyverse) library(tidymodels) library(ggplot2) library(countrycode) library(plotly) library(sysfonts) library(showtext) library(glue) library(scales) library(janitor) library(DALEXtra) library(dbarts) #Loading the datasets df_childhood &lt;- read_csv(&quot;https://raw.githubusercontent.com/mesdi/blog/main/childhood.csv&quot;) df_household &lt;- read_csv(&quot;https://raw.githubusercontent.com/mesdi/blog/main/household.csv&quot;) #Joining them by country and time df &lt;- df_childhood %&gt;% left_join(df_household, by = c(&quot;country&quot;, &quot;time&quot;)) %&gt;% na.omit() #Wrangling the dataset df_tidy &lt;- df %&gt;% mutate(household = round(household, 2), childhood = round(childhood, 2), age = str_replace(age, &quot;_&quot;, &quot;-&quot;), country_name = countrycode(country, &quot;genc3c&quot;, &quot;country.name&quot;) ) #Best 20 countries based on the household net worth in their last year df_tidy %&gt;% group_by(country) %&gt;% slice_max(time) %&gt;% slice_max(household, n=20) %&gt;% mutate(age = fct_reorder(age, childhood, .desc = TRUE), country_name = fct_reorder(country_name, household, .desc = TRUE)) %&gt;% ggplot(aes(x=country_name, y=childhood, fill = age, #Hover text of the barplot text = glue(&quot;{country}\\n%{childhood}\\n{age}\\nChildhood education&quot;))) + geom_col() + geom_line(aes(y=household/2, group = 1), color= &quot;skyblue&quot;, size=1) + #Adding the household net worth as a second(dual) y-axis scale_y_continuous(sec.axis = sec_axis(~.*2)) + scale_fill_viridis_d(name = &quot;&quot;) + xlab(&quot;&quot;) + ylab(&quot;&quot;) + theme_minimal() + theme( axis.text.x = element_text(angle = 60), axis.text.y = element_blank(), axis.text.y.right = element_blank(), panel.grid = element_blank(), legend.position = &quot;none&quot; ) -&gt; p #adding google font font_add_google(name = &quot;Henny Penny&quot;, family = &quot;henny&quot;) showtext_auto() #setting font family for ggplotly font &lt;- list( family= &quot;Henny Penny&quot;, size =5 ) #Plotly chart ggplotly(p, tooltip = c(&quot;text&quot;)) %&gt;% #Hover text of the line style(text = glue(&quot;{unique(p$data$country)}\\n%{unique(p$data$household)}\\nHousehold net worth&quot;),traces = 6) %&gt;% layout(font=font) This graph can show us what the household net worth looks like based on the education rate for each of the ages in the data set. Yellow represents age 3, teal is age 4, and purple is age 5. The blue trend line shows the household net worth for each country in the data. head(df_tidy) ## # A tibble: 6 × 6 ## country age time childhood household country_name ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 AUS AGE-3 2010 71.8 347. Australia ## 2 AUS AGE-3 2013 62.3 366. Australia ## 3 AUS AGE-3 2014 69.4 383. Australia ## 4 AUS AGE-3 2015 68.4 402. Australia ## 5 AUS AGE-3 2016 63.3 428. Australia ## 6 AUS AGE-3 2017 66.0 439. Australia In order to run the two different packages we use in this tutorial, dbarts and tidymodels, we start by splitting our data into a training set and and a test set. This way we can train the model and evaluate the performance on the test set. #Splitting the data into train and test sets set.seed(1234) df_split &lt;- df_tidy %&gt;% #Converting the levels to variables for modeling pivot_wider(names_from = age, values_from = childhood) %&gt;% clean_names() %&gt;% na.omit() %&gt;% initial_split() df_train &lt;- training(df_split) df_test &lt;- testing(df_split) df_train ## # A tibble: 216 × 7 ## country time household country_name age_3 age_4 age_5 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 SVN 2015 324. Slovenia 82.8 89.3 91.8 ## 2 ITA 2014 575. Italy 92.0 96.0 97.0 ## 3 JPN 2012 571. Japan 78 93.8 94.6 ## 4 LUX 2011 391. Luxembourg 72.0 94.6 96.7 ## 5 ITA 2011 500. Italy 94.4 98.7 99.6 ## 6 ITA 2016 578. Italy 92.4 95.9 96.4 ## 7 ESP 2017 392. Spain 96.4 97.7 97.1 ## 8 GRC 2019 362. Greece 34.9 76.0 95.2 ## 9 DEU 2015 469. Germany 93.3 96.7 98.1 ## 10 LTU 2012 203. Lithuania 71.4 75 77.0 ## # ℹ 206 more rows 3.2 dbarts package Using the dbarts package, we can fit a model using the column numbers from our data. Our response variables called x.train is formed using the columns for age 3, age 4, and age 5 while y.train is formed using our response variable column. We can also set keeptrees = TRUE in order to view some examples of what variable a tree chose, what the split rule is, and how long before the tree terminates. # Fitting a BART model with default 1,000 iterations of 200 trees set.seed(4343) bartFit &lt;- bart(x.train = as.matrix(df_train[,5:7]), y.train = as.numeric(unlist(df_train[,3])),keeptrees = TRUE, ndpost = 1000) ## ## Running BART with numeric y ## ## number of trees: 200 ## number of chains: 1, number of threads 1 ## tree thinning rate: 1 ## Prior: ## k prior fixed to 2.000000 ## degrees of freedom in sigma prior: 3.000000 ## quantile in sigma prior: 0.900000 ## scale in sigma prior: 0.004462 ## power and base for tree prior: 2.000000 0.950000 ## use quantiles for rule cut points: false ## proposal probabilities: birth/death 0.50, swap 0.10, change 0.40; birth 0.50 ## data: ## number of training observations: 216 ## number of test observations: 0 ## number of explanatory variables: 3 ## init sigma: 103.908284, curr sigma: 103.908284 ## ## Cutoff rules c in x&lt;=c vs x&gt;c ## Number of cutoffs: (var: number of possible c): ## (1: 100) (2: 100) (3: 100) ## Running mcmc loop: ## iteration: 100 (of 1000) ## iteration: 200 (of 1000) ## iteration: 300 (of 1000) ## iteration: 400 (of 1000) ## iteration: 500 (of 1000) ## iteration: 600 (of 1000) ## iteration: 700 (of 1000) ## iteration: 800 (of 1000) ## iteration: 900 (of 1000) ## iteration: 1000 (of 1000) ## total seconds in loop: 2.164798 ## ## Tree sizes, last iteration: ## [1] 2 2 2 3 4 3 4 2 2 2 3 2 2 4 2 2 2 2 ## 2 3 2 1 2 4 2 2 3 2 2 2 2 2 2 1 2 1 2 1 ## 2 5 2 2 3 3 4 2 2 1 3 2 2 2 2 1 3 2 1 2 ## 1 2 2 2 3 2 2 1 3 2 2 2 4 2 3 2 2 1 3 2 ## 2 3 4 2 4 2 2 3 2 2 2 2 2 2 3 2 2 3 2 3 ## 4 2 2 2 3 2 2 2 2 2 3 2 4 2 2 1 2 2 2 2 ## 2 2 3 2 2 2 4 2 1 3 2 2 4 2 2 2 3 3 4 3 ## 2 2 2 3 2 2 2 4 2 2 2 1 2 2 2 2 3 2 2 2 ## 1 2 2 3 3 3 2 2 2 2 3 1 2 2 3 2 3 3 2 2 ## 1 4 3 2 2 2 2 2 2 2 2 2 2 2 3 3 2 2 2 2 ## 2 2 ## ## Variable Usage, last iteration (var:count): ## (1: 77) (2: 91) (3: 86) ## DONE BART # Extracting trees from model trees &lt;- extract(bartFit, &quot;trees&quot;) # Looking at some examples of trees from model bartFit$fit$plotTree(chainNum = 1, sampleNum = 3, treeNum = 1) bartFit$fit$plotTree(chainNum = 1, sampleNum = 3, treeNum = 140) Using the bartMan package, we can look at some more interesting visualizations that show us some model diagnostics as well as what our trees look like in a fit model. # Loading packages for BART visualization library(bartMan) library(ggridges) bartDiag(model = bartFit, response = &quot;household&quot;, burnIn = 1000, data = df_tidy) For less computational time and simplicity, we reduce the number of trees as well as the number of iterations for each tree. We fit a new model with the same variables with 50 trees for 10 iterations. # Fitting another BART model with fewer trees and less iterations set.seed(4343) bartFit50 &lt;- bart(x.train = as.matrix(df_train[,5:7]), y.train = as.numeric(unlist(df_train[,3])), keeptrees = TRUE, ntree = 50, ndpost = 10) ## ## Running BART with numeric y ## ## number of trees: 50 ## number of chains: 1, number of threads 1 ## tree thinning rate: 1 ## Prior: ## k prior fixed to 2.000000 ## degrees of freedom in sigma prior: 3.000000 ## quantile in sigma prior: 0.900000 ## scale in sigma prior: 0.004462 ## power and base for tree prior: 2.000000 0.950000 ## use quantiles for rule cut points: false ## proposal probabilities: birth/death 0.50, swap 0.10, change 0.40; birth 0.50 ## data: ## number of training observations: 216 ## number of test observations: 0 ## number of explanatory variables: 3 ## init sigma: 103.908284, curr sigma: 103.908284 ## ## Cutoff rules c in x&lt;=c vs x&gt;c ## Number of cutoffs: (var: number of possible c): ## (1: 100) (2: 100) (3: 100) ## Running mcmc loop: ## total seconds in loop: 0.052520 ## ## Tree sizes, last iteration: ## [1] 4 3 2 2 3 2 2 2 3 2 2 2 4 3 2 2 2 2 ## 3 2 2 2 2 2 3 2 2 2 2 2 2 2 4 2 2 2 2 2 ## 3 2 2 2 4 3 1 3 2 3 2 2 ## ## Variable Usage, last iteration (var:count): ## (1: 19) (2: 26) (3: 22) ## DONE BART # Extracting the tree data trees_data50 &lt;- extractTreeData(bartFit50, df_tidy) # Visualizing what each of the 50 trees look like over their 10 iterations plotTrees(trees = trees_data50, fillBy = NULL, sizeNodes = TRUE) # Viewing all 10 iterations of one tree plotTrees(trees = trees_data50, treeNo = 13) This plot shows us all of the iterations of the trees fit in the reduced model. Each color represents the variable that the tree is splitting on, and the gray represents a stump/leaf, or a terminal node. Now, we are creating a couple more visuals of the trees using our model with 50 trees and 10 iterations. To start, we use bartMan again to create a bar plot that shows how many times each specific structure of tree, including which variable the tree splits on (but not its splitting rule value), shows up within the model. We also create a density plot that shows the splitting variables and the frequency at which each splitting rule value is chosen. # Creating bar plot showing frequency of 8 most common trees from model treeBarPlot(trees_data50, topTrees = 8, iter = NULL) # Creating density plot of variable split levels values splitDensity(trees = trees_data50, data = df_tidy, display = &#39;ridge&#39;) These visuals can be interesting to look at and interpret, but there is a discrepancy in the colors that are shown between the before tree plots, the density plot, and the bar plot. There is no legend argument for the treeBarPlot, so we do not actually know which variables are most commonly split on and where in the tree. 3.3 tidymodels package Now we are using the tidymodels package to fit our BART models. There are different steps to this package than there are for dbarts, but if you are familiar with machine learning in R, you should be able to follow along better. #Preprocessing df_rec &lt;- recipe(household ~ age_3 + age_4 + age_5, data = df_train) #Modeling with BART df_spec &lt;- parsnip::bart() %&gt;% set_engine(&quot;dbarts&quot;, keeptrees = TRUE) %&gt;% set_mode(&quot;regression&quot;) #Workflow df_wf &lt;- workflow() %&gt;% add_recipe(df_rec) %&gt;% add_model(df_spec) #cross-validation for resamples set.seed(12345) df_folds &lt;- vfold_cv(df_train) #Resampling for the accuracy metrics set.seed(98765) df_rs &lt;- df_wf %&gt;% fit_resamples(resamples = df_folds) #Computes the accuracy metrics collect_metrics(df_rs) ## # A tibble: 2 × 6 ## .metric .estimator mean n std_err .config ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 rmse standard 85.2 10 4.79 Preprocessor1_Model1 ## 2 rsq standard 0.528 10 0.0458 Preprocessor1_Model1 The output we see above are quality metrics for our model. Our RMSE average value shows the difference between the observed and predicted values of household net worth to be 85.2. The variable for household net worth ranges from 134 to 824. Given this context, our model has an could be considered to have a decent performance, but it could be better. The \\(R^2\\) value indicates the model fit. We observe a value of 0.528, which we would like to be closer to 1 in order for the model to explain more variability in the data. For this second model, we are using grid search to tune the priors of the model. These priors include the trees, terminal node coefficient, and the exponential component of the prior distribution for these terminal node parameters. # Model tuning with grid search df_spec &lt;- parsnip::bart( trees = tune(), prior_terminal_node_coef = tune(), prior_terminal_node_expo = tune() ) %&gt;% set_engine(&quot;dbarts&quot;) %&gt;% set_mode(&quot;regression&quot;) #parameter object rf_param &lt;- workflow() %&gt;% add_model(df_spec) %&gt;% add_recipe(df_rec) %&gt;% extract_parameter_set_dials() %&gt;% finalize(df_train) #space-filling design with integer grid argument df_reg_tune &lt;- workflow() %&gt;% add_recipe(df_rec) %&gt;% add_model(df_spec) %&gt;% tune_grid( df_folds, grid = 20, param_info = rf_param, metrics = metric_set(rsq) ) #Selecting the best parameters according to the r-square rf_param_best &lt;- select_best(df_reg_tune, metric = &quot;rsq&quot;) %&gt;% select(-.config) #Final estimation with the object of best parameters final_df_wflow &lt;- workflow() %&gt;% add_model(df_spec) %&gt;% add_recipe(df_rec) %&gt;% finalize_workflow(rf_param_best) set.seed(12345) final_df_fit &lt;- final_df_wflow %&gt;% last_fit(df_split) #Computes final the accuracy metrics collect_metrics(final_df_fit) ## # A tibble: 2 × 4 ## .metric .estimator .estimate .config ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 rmse standard 88.6 Preprocessor1_Model1 ## 2 rsq standard 0.616 Preprocessor1_Model1 # A tibble: 2 x 4 # .metric .estimator .estimate .config # &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; #1 rmse standard 84.5 Preprocessor1_Model1 #2 rsq standard 0.645 Preprocessor1_Model1 The RMSE average value shows the difference between the observed and predicted values of household net worth to be 84.5. This is just slightly better than the previous model. For this second model, we observe a value of 0.645, which is better than the first model, but still a bit far from 1. 3.4 Example 2: Classification Now we are using classification with the tidymodels package instead of regression. The Palmer Penguins data set that lives in a package we can load easily here. We can use this model to predict what species a penguin is out of three different observed options: Adelie, Chinstrap, and Gentoo. This data set contains measurements from many observations of the three different species of penguins. These data were collected from 2007 - 2009 by Dr. Kristen Gorman with the Palmer Station Long Term Ecological Research Program, part of the US Long Term Ecological Research Network. The data were imported directly from the Environmental Data Initiative (EDI) Data Portal, and are available for use by CC0 license (“No Rights Reserved”) in accordance with the Palmer Station Data Policy. # Loading data library(palmerpenguins) data(penguins) head(penguins) ## # A tibble: 6 × 8 ## species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 Adelie Torgersen 39.1 18.7 181 3750 ## 2 Adelie Torgersen 39.5 17.4 186 3800 ## 3 Adelie Torgersen 40.3 18 195 3250 ## 4 Adelie Torgersen NA NA NA NA ## 5 Adelie Torgersen 36.7 19.3 193 3450 ## 6 Adelie Torgersen 39.3 20.6 190 3650 ## # ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt; 3.5 dbarts package To start to build our models, we again have to split the data into training and test sets. #Splitting the data into train and test sets set.seed(1234) penguin_split &lt;- penguins %&gt;% na.omit() %&gt;% initial_split() penguin_train &lt;- training(penguin_split) penguin_test &lt;- testing(penguin_split) Now we will fit the model in a similar way to the regression model from before, except now with our penguin data specifications. We are using the variables for bill length, bill depth, flipper length, and body mass of the penguins to predict their species. We can view some examples of trees within the model as well. # Fitting a BART model with 200 trees with 1000 iterations set.seed(4343) p.bartFit &lt;- bart(x.train = as.matrix(penguin_train[,3:6]), y.train = as.numeric(unlist(penguin_train[,1])), keeptrees = TRUE, ndpost = 1000) ## ## Running BART with numeric y ## ## number of trees: 200 ## number of chains: 1, number of threads 1 ## tree thinning rate: 1 ## Prior: ## k prior fixed to 2.000000 ## degrees of freedom in sigma prior: 3.000000 ## quantile in sigma prior: 0.900000 ## scale in sigma prior: 0.003171 ## power and base for tree prior: 2.000000 0.950000 ## use quantiles for rule cut points: false ## proposal probabilities: birth/death 0.50, swap 0.10, change 0.40; birth 0.50 ## data: ## number of training observations: 249 ## number of test observations: 0 ## number of explanatory variables: 4 ## init sigma: 0.255188, curr sigma: 0.255188 ## ## Cutoff rules c in x&lt;=c vs x&gt;c ## Number of cutoffs: (var: number of possible c): ## (1: 100) (2: 100) (3: 100) (4: 100) ## Running mcmc loop: ## iteration: 100 (of 1000) ## iteration: 200 (of 1000) ## iteration: 300 (of 1000) ## iteration: 400 (of 1000) ## iteration: 500 (of 1000) ## iteration: 600 (of 1000) ## iteration: 700 (of 1000) ## iteration: 800 (of 1000) ## iteration: 900 (of 1000) ## iteration: 1000 (of 1000) ## total seconds in loop: 1.796290 ## ## Tree sizes, last iteration: ## [1] 2 2 2 2 1 2 3 2 2 2 2 2 2 5 2 2 2 1 ## 3 4 2 3 2 2 2 2 3 3 3 2 3 3 3 2 1 2 2 2 ## 2 4 2 2 3 1 2 3 1 2 4 2 3 3 6 3 2 2 2 2 ## 3 2 3 3 2 2 5 2 2 2 2 3 2 2 2 3 2 1 2 1 ## 2 2 2 2 3 4 4 2 2 4 3 3 3 3 2 2 2 4 3 2 ## 3 2 2 2 2 2 2 2 3 2 2 3 4 3 2 3 3 3 2 3 ## 2 5 3 3 1 2 2 2 1 2 2 3 2 4 1 2 2 2 3 2 ## 4 2 1 3 2 2 3 3 2 3 2 2 3 3 2 2 1 3 2 3 ## 2 2 2 3 2 3 2 2 2 1 2 2 3 3 2 3 3 3 2 2 ## 2 2 2 2 3 2 3 2 2 2 2 2 2 4 2 1 2 2 2 2 ## 2 2 ## ## Variable Usage, last iteration (var:count): ## (1: 69) (2: 86) (3: 69) (4: 51) ## DONE BART trees &lt;- extract(p.bartFit, &quot;trees&quot;) # Looking at some examples of trees from model p.bartFit$fit$plotTree(chainNum = 1, sampleNum = 3, treeNum = 112) p.bartFit$fit$plotTree(chainNum = 1, sampleNum = 3, treeNum = 140) bartDiag(model = p.bartFit, data = penguins, response = &quot;species&quot;, burnIn = 0) Here we can see some diagnostic plots of our model. The two upper rows show if our model has a reasonable performance of the residuals. Using the bartMan package we can create similar visualizations to view the trends of the shapes of the trees and their splitting variables and values. We will again start with a smaller model with less trees and less iterations. # Fitting another BART model with fewer trees and less iterations set.seed(4343) p.bartFit50 &lt;- bart(x.train = as.matrix(penguin_train[,3:6]), y.train = as.numeric(unlist(penguin_train[,1])), keeptrees = TRUE, ntree = 50, ndpost = 10) ## ## Running BART with numeric y ## ## number of trees: 50 ## number of chains: 1, number of threads 1 ## tree thinning rate: 1 ## Prior: ## k prior fixed to 2.000000 ## degrees of freedom in sigma prior: 3.000000 ## quantile in sigma prior: 0.900000 ## scale in sigma prior: 0.003171 ## power and base for tree prior: 2.000000 0.950000 ## use quantiles for rule cut points: false ## proposal probabilities: birth/death 0.50, swap 0.10, change 0.40; birth 0.50 ## data: ## number of training observations: 249 ## number of test observations: 0 ## number of explanatory variables: 4 ## init sigma: 0.255188, curr sigma: 0.255188 ## ## Cutoff rules c in x&lt;=c vs x&gt;c ## Number of cutoffs: (var: number of possible c): ## (1: 100) (2: 100) (3: 100) (4: 100) ## Running mcmc loop: ## total seconds in loop: 0.055579 ## ## Tree sizes, last iteration: ## [1] 3 2 2 2 2 2 5 2 5 3 3 2 4 4 3 3 5 4 ## 2 1 2 1 3 2 3 3 2 2 3 2 2 2 2 2 3 2 5 2 ## 2 2 2 2 2 2 3 2 2 3 2 2 ## ## Variable Usage, last iteration (var:count): ## (1: 20) (2: 25) (3: 20) (4: 13) ## DONE BART # Extracting the tree data p.trees_data &lt;- extractTreeData(p.bartFit50, penguins) # Visualizing what each of the 50 trees look like over their 10 iterations plotTrees(trees = p.trees_data, fillBy = NULL, sizeNodes = TRUE) # Viewing all 10 iterations of one tree plotTrees(trees = p.trees_data, treeNo = 13) In visualizing our model of each of the 50 trees each with 10 iterations, we can see that each of the four variables have appeared in our trees as splitting variables… But this time, since we have more variables in the data to choose from, we can use these next plots to help us see which variables are considered most important in the model. # Creating bar plot showing frequency of 10 most common trees from model treeBarPlot(p.trees_data, iter = NULL, topTrees = 10, removeStump = FALSE) # Creating density plot of variable split levels values splitDensity(trees = p.trees_data, data = df_tidy, display = &#39;ridge&#39;) We can see from our bar plot of the 8 most common tree configurations, that we have idk bro 3.6 tidymodels package When we are fitting our model using tidymodels, we use a very similar layout to the code we use for the regression model. The differences here are that we would change the mode to classification rather than regression and our model evaluation metrics also need to change. Using the diagnostic plots from the dbarts model, we can decide to take out the body mass variable from this model. #Preprocessing penguin_rec &lt;- recipe(species ~ bill_length_mm + bill_depth_mm + flipper_length_mm , data = penguin_train) #Modeling with BART penguin_spec &lt;- parsnip::bart() %&gt;% set_engine(&quot;dbarts&quot;) %&gt;% set_mode(&quot;classification&quot;) #Workflow penguin_wf &lt;- workflow() %&gt;% add_recipe(penguin_rec) %&gt;% add_model(penguin_spec) #cross-validation for resamples set.seed(12345) penguin_folds &lt;- vfold_cv(penguin_train) classification_metrics &lt;- metric_set(accuracy) # Resampling for the classification metrics penguin_rs &lt;- penguin_wf %&gt;% fit_resamples(resamples = penguin_folds, metrics = classification_metrics) # Compute the classification metrics collect_metrics(penguin_rs) ## # A tibble: 1 × 6 ## .metric .estimator mean n std_err .config ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 accuracy multiclass 0.642 10 0.0211 Preprocessor1_Model1 The output from this model shows the proportion of correctly classified instances of species from our model. So, our model correctly classifies species of penguin 64% of the time. This value is not much higher than 50%, so we might want to look a bit more at fixing our model. This next model has uses a binary output sex rather than a three-level factor like the species variable. #Preprocessing penguin_rec &lt;- recipe(sex ~ bill_length_mm + bill_depth_mm+ flipper_length_mm + species, data = penguin_train) #Modeling with BART penguin_spec &lt;- parsnip::bart() %&gt;% set_engine(&quot;dbarts&quot;) %&gt;% set_mode(&quot;classification&quot;) #Workflow penguin_wf &lt;- workflow() %&gt;% add_recipe(penguin_rec) %&gt;% add_model(penguin_spec) #cross-validation for resamples set.seed(12345) penguin_folds &lt;- vfold_cv(penguin_train) classification_metrics &lt;- metric_set(accuracy, precision) # Resampling for the classification metrics penguin_rs &lt;- penguin_wf %&gt;% fit_resamples(resamples = penguin_folds, metrics = classification_metrics) # Compute the classification metrics collect_metrics(penguin_rs) ## # A tibble: 2 × 6 ## .metric .estimator mean n std_err .config ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 accuracy binary 0.880 10 0.0215 Preprocessor1_Model1 ## 2 precision binary 0.880 10 0.0335 Preprocessor1_Model1 We are able to view both accuracy and precision estimates for this model as it has a binary response variable. From the average accuracy, we can see that this model correctly classifies a penguin’s sex 88% of the time. We could say here that the model is pretty good. The precision is calculated using \\(\\frac{\\text{True Positive}}{\\text{True Positive + False Positive}}\\). If the cost of false negatives is high in our model, we want to minimize how many there are. In the context of our model, a positive value is male while a negative value is female. With a precision value of 88%, we can say that when the model predicts a positive outcome (male) it is correct about 88% of the time. 3.7 References AlanInglis. (n.d.). GitHub - AlanInglis/bartMan: Visualisations for posterior evaluation of BART models. GitHub. https://github.com/AlanInglis/bartMan?tab=readme-ov-file Bayesian additive regression trees (BART) - bart. - bart • parsnip. (n.d.). https://parsnip.tidymodels.org/reference/bart.html Disci, S. (2022, December 8). The effect of childhood education on wealth: Modeling with bayesian additive regression trees (BART): R-bloggers. R. https://www.r-bloggers.com/2022/12/the-effect-of-childhood-education-on-wealth-modeling-with-bayesian-additive-regression-trees-bart/#google_vignette Inglis, A., Parnell, A. C., &amp; Hurley, C. (2024). Visualisations for Bayesian Additive Regression Trees. Journal of Data Science, Statistics, and Visualisation, 4(1). https://doi.org/10.52933/jdssv.v4i1.79 Introduction to palmerpenguins. (n.d.). https://allisonhorst.github.io/palmerpenguins/articles/intro.html "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
